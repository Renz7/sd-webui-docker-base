################################################################################
# Dockerfile that builds 'yanwk/sd-webui-base:bulky'.
# A environment not only for running AUTOMATIC1111/stable-diffusion-webui,
# but also includes all compile tools for Magma, PyTorch & xFormers.
# Image size will be large.
# Building this image could timeout on GitHub Actions, so better build it locally.
# Beware, check the version numbers before build!
################################################################################

FROM opensuse/leap:15.4

LABEL maintainer="code@yanwk.fun"

WORKDIR /root

# https://gitlab.com/nvidia/container-images/cuda/-/tree/master/dist
# https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html
RUN --mount=type=cache,target=/var/cache/zypp \
    set -eu \
    && printf "\
[cuda-opensuse15-x86_64]\n\
name=cuda-opensuse15-x86_64\n\
baseurl=https://developer.download.nvidia.com/compute/cuda/repos/opensuse15/x86_64\n\
enabled=1\n\
gpgcheck=1\n\
gpgkey=https://developer.download.nvidia.com/compute/cuda/repos/opensuse15/x86_64/D42D0685.pub\n" \
        > /etc/zypp/repos.d/cuda-opensuse15.repo \
    && printf "\
[intel-oneapi]\n\
name=intel-oneapi\n\
baseurl=https://yum.repos.intel.com/oneapi\n\
enabled=1\n\
gpgcheck=1\n\
gpgkey=https://yum.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB\n" \
        > /etc/zypp/repos.d/intel-oneapi.repo \
    && zypper --gpg-auto-import-keys \
        install --no-confirm --no-recommends --auto-agree-with-licenses \
            git make cmake ninja find \
            fish shadow mlocate aria2 \
            gperftools-devel libgthread-2_0-0 Mesa-libGL1 \
            python310 python310-pip python310-devel \
            intel-oneapi-compiler-dpcpp-cpp intel-oneapi-compiler-fortran \
            intel-oneapi-mkl intel-oneapi-mkl-devel \
            cuda-cudart-11-8 cuda-compat-11-8 \
            cuda-libraries-11-8 cuda-nvtx-11-8 libnpp-11-8 libcublas-11-8 \
            cuda-command-line-tools-11-8 cuda-libraries-devel-11-8 \
            cuda-minimal-build-11-8 cuda-cudart-devel-11-8 cuda-nvprof-11-8 \
            cuda-nvml-devel-11-8 libcublas-devel-11-8 libnpp-devel-11-8 \
            cuda-cccl-11-8 cuda-nvcc-11-8 cuda-nvrtc-devel-11-8 

RUN ln -s /usr/bin/python3 /usr/bin/python

# Use TCMALLOC from gperftools.
ENV LD_PRELOAD=libtcmalloc.so

# PATH for NVCC
ENV PATH="${PATH}:/usr/local/cuda-11.8/bin"
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/cuda-11.8/lib64"

RUN --mount=type=cache,target=/root/.cache/pip \
    pip install ninja wheel setuptools numpy \
    && pip install --pre torch torchvision --force-reinstall \
        --index-url https://download.pytorch.org/whl/nightly/cu118 

# Compile-install xformers
# Reduce build-targets to save time on compiling!
# https://github.com/facebookresearch/xformers/blob/main/README.md#install-troubleshooting
# https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/
RUN --mount=type=cache,target=/root/.cache/pip \
    cd /root \
    && git clone --depth=1 --recurse-submodules --shallow-submodules \
        https://github.com/facebookresearch/xformers.git \
    && cd xformers \
    && pip install -r requirements.txt 

ENV TORCH_CUDA_ARCH_LIST="6.1;7.5;8.0;8.6"

RUN --mount=type=cache,target=/root/xformers/build \
    --mount=type=cache,target=/root/xformers/dist \
    cd /root/xformers \
    && python setup.py bdist_wheel -d /root/wheels

# 'build' folder is mounted as cache and gone afterwards. There's no need to keep src.
# But we keep wheel file for any further use.
RUN rm -rf /root/xformers \
    && pip install /root/wheels/*.whl

# All remaining deps are described in txt
COPY ["requirements.txt","/root/"]
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r /root/requirements.txt

# Fix for TensorRT
WORKDIR /usr/lib/python3.10/site-packages/tensorrt
RUN ln -s libnvinfer_plugin.so.8 libnvinfer_plugin.so.7 \
    && ln -s libnvinfer.so.8 libnvinfer.so.7
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/lib/python3.10/site-packages/tensorrt"

# Create a low-privilege user.
RUN sed -i 's/^CREATE_MAIL_SPOOL=yes/CREATE_MAIL_SPOOL=no/' /etc/default/useradd \
    && mkdir -p /home/runner /home/scripts \
    && groupadd runner \
    && useradd runner -g runner -d /home/runner \
    && chown runner:runner /home/runner /home/scripts

COPY --chown=runner:runner scripts/. /home/scripts/

USER runner:runner
VOLUME /home/runner
WORKDIR /home/runner
ENV CLI_ARGS=""
EXPOSE 7860
STOPSIGNAL SIGINT
CMD bash /home/scripts/entrypoint.sh
